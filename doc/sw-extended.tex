%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Space Warps System Paper
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[useAMS,usenatbib,a4paper]{mn2e}
%% letterpaper
%% a4paper

\voffset=-0.6in

% Packages:
\input psfig.sty
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}

% Macros:
\input{macros.tex}
\input{addresses.tex}

\def\indic#1{\mathbb{I}\left({#1}\right)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title[\sw]
{\SW Extended! Snappy Titles!}

\author[Davis et al.]{%
  \input{sw-system-authors.tex}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\date{to be submitted to ?!?!}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}\pubyear{2014}

\maketitle

\label{firstpage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

\todo{Chris}{Do abstract!}

\end{abstract}

% Full list of options at http://www.journals.uchicago.edu/ApJ/instruct.key.html

\begin{keywords}
  gravitational lensing   --
  methods: statistical    --
  methods: citizen science
\end{keywords}

\setcounter{footnote}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}


% \section{Introduction}
% \label{sec:intro}
% \section{Offline \SW}
% \label{sec:offline}
% \subsection{Formalism}
% \label{sec:offline:formalism}
% \subsection{Training}
% \label{sec:design:training}
% \section{Results}
% \label{sec:results}
% \section{Discussion}
% \label{sec:discuss}
% \section{Conclusions}
% \label{sec:conclude}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Dataset}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% TODO:
% Kamal Nigam, Andrew McCallum and Tom Mitchell. Semi-supervised Text Classification Using EM. In Chapelle, O., Zien, A., and Scholkopf, B. (Eds.) Semi-Supervised Learning. MIT Press: Boston. 2006.
% according to
% http://www.mblondel.org/journal/2010/06/21/semi-supervised-naive-bayes-in-python/#more-126
% this paper would be an example of the sort of thinking I had with the EM
% algorithm (not quite what was implimented in stage 2 at phil's request),
% where the E step just does the unlabeled, and the M step uses both labeled
% and unlabeled data

\section{Formalism}
\label{sec:formalism}

\todo{Chris}{This section will describe the different ways we can use the data
  we got from SpaceWarps to do a beter job with classifications. So we can then
  look at the way SpaceWarps updates the PL, PD, and p's of the objects, either
  via offline, using both/either/neither training and test data (in either online or offline
contexts), manipulating initializations, etc. We could also see what the
benefits are for using the known lens information. Finally, we should examine the
benefits of using a validation dataset (using information we already have!) to
improve our estimates.}
\flag{Chris}{I don't like using $p^0$ to both represent the true prior prior
and our estimate of the correct prior according to the EM algorithm.}

\sw keeps track of the following parameters:
\begin{itemize}
  \item{$C_{ij}$, the classification the $i$-th volunteer made of the $j$-th
      image. $C_{ij}$ may take on three values:
      0, 1, or empty. Since volunteers do not see most images, the vast
    majority of $C_{ij}$ are blank.}
    \item{$PD_{i}$, the probability, given that the image is a dud, that
        $i$-th the volunteer will classify it as a dud. The
      probability, given that the image is a dud, that the volunteer will
    classify it as a lens follows as $1 - PD_{i}$.}
  \item{$PL_{i}$, the probability, given that the image is actually a
      lens, that the $i$-th volunteer will classify it as being a lens. The
      probability, given that the image is a lens, that the volunteer will
    classify it as a dud follows as $1 - PL_{i}$.}
  \item{$p_j$, the probability that
      the $j$-th image $z_{j}$ is a lens given the current observations and skills of the
  volunteers who classified it.}
  \item{$p^{0}$, the prior probability that an object is a lens.}
\end{itemize}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\subsection{The Online System}
\label{sec:formalism:online}
In \sw, this is fixed at $2 \times 10^{-4}$, or the expectation that
around 100 lenses will be found in 430,000 images. Because \sw is an online
system that constantly reevaluates most of the above parameters (except $p_0$
and any non-blank $C_{ij}$) in order to promote likely lenses\footnote{Note
that this does not change the probability that a volunteer will actually draw
said image.} or to retire likely duds,\footnote{Images whose probability of
being a lens drops below a certain threshold are removed from the active
dataset.} we augment $p$, $PL$, and $PD$ as $p_j^k$, the evaluation of
$p_j$ at time $k$. \sw uses Bayes's Theorem to update $p_j^{(k + 1)}$ for
some new evaluation $C_{ij}$\footnote{There is no superscript for $C_{ij}$
because each user only sees an image once.}:
\begin{align}
  p_j^{(k + 1)} &= \left ( \frac{C_{ij} PL_{i}^{k}
  }{PL_{i}^{k} p_j^k + (1 - PD_{i}^{k})(1 -
  p_j^k)}
  \right. \notag \\ & \; \left . +
  \frac{(1 - C_{ij}) (1 - PL_{i}^{k})
  }{(1 - PL_{i}^{k}) p_j^k + PD_{i}^{k}(1 -
  p_j^k)} \right ) p_j^k \ ,
\end{align}
The first term on the right hand side is the probability update for evaluating
the object to be a lens, while the second term is the probability that the
image is a lens if the volunteer evaluates it to be a dud.  (For example, an
obtuse volunteer who always perfectly incorrectly classifies an image will
actually change the probability exactly the same as one who always perfectly
correctly classifies an image, given that the estimate of the obtuse
volunteer's skill ($PL_{i} = 0$) is accurate.)

\sw only updates the volunteer's $PL_{i}$ and $PD_{i}$ after volunteer $C_i$
classifies a training image:

\begin{align}
  PL_{i}^{(k + 1)} &= \frac{PL_{i}^{k} (NL_{i}^{k} + M) + \mathbb{I}[C_{ij} =
  z_{j}]}{NL_{i}^{k} + M + z_{j}} \\
  PD_{i}^{(k + 1)} &= \frac{PD_{i}^{k} (ND_{i}^{k} + M) + \mathbb{I}[C_{ij} =
  z_{j}]}{ND_{i}^{k} + M + z_{j}}
\end{align}
where $ND_{i}^{k}$ and $NL_{i}^{k}$ refer to the number of training lenses and
training duds observed by the $i$-th volunteer at time $k$, $z_{j}$ refers to
the true state of the $j$-th image (1 is LENS, 0 is DUD), and $M = 4$ is a
smoothing factor empirically derived to smooth the skill classification of new
volunteers.

With these update rules plus an initialization of $PD_{i} = PL_{i} = 0.5$ and
$p^{0} = 2 \times 10^{-4}$, the online update system is fully specified.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\subsection{An Offline Expectation Maximization Approach}
\label{sec:formalism:em}
Using the above notation but expanding $p^{0}$ to $p_{ij}^{0}$ (allowing, e.g. for
the distribution of training images to differ for each volunteer, perhaps based on
the number of images they have observed, or to allow a particular image to be
more likely to be drawn), the complete log-likelihood for this model may be
specified:
\begin{multline}
  \mathrm{CLL}(C_{ij}, z_{j}, PL_{i}, PD_{i}, p_{ij}^{0}) \\ = \sum_{i} \sum_{j \in \Omega_i} C_{ij} z_{j} \log PL_{i} +
      (1 - C_{ij}) z_j \log (1 -
      PL_{i}) \\ + (1 - C_{ij}) (1 - z_j) \log PD_{i} + C_{ij} (1 - z_j) \log (1 - PD_{i}) \\ + z_j \log p_{ij}^{0} +
      (1 - z_j ) \log(1 - p_{ij}^{0})
\end{multline}
where $\Omega_i$ is the set of all images volunteer $i$ has observed in $\Omega$,
the set of all images in the program.\footnote{Because the probability that a
  viewer views a given image (given it is a training or test image) is random,
I choose to simply ignore the unobserved images.} We can use this complete
log-likelihood to derive an offline expectation maximization algorithm for
determining the lens probabilities, user skills, and lens priors.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\subsubsection{E-Step}
\label{sec:formalism:em:estep}
\todo{Chris}{reword. The maximization here is over the zj's, so word to
  make that clear. The E-Step is just taking the expected complete
log-likelihood, or the expectation value over $P(\cdot \ | x, \phi)$.}
The E-Step is maximizing the complete log-likelihood with respect to the image
probability $p_j$.  This is equivalent to replacing binary $z_j$ with
probability $p_j$:
\todo{Chris}{replace this with equivalent like eq1}
\begin{align}
  p_j &= \frac{1}{N_j} \sum_{i \in \Omega_j} P(z_j = 1 \ | \ C_{ij} ; \Phi) =
  \frac{1}{N_j} \sum_{i \in \Omega_j} \frac{ P(C_{ij} \ | \ z_j = 1; \Phi)
P(z_j = 1 ; \Phi)}{P(C_{ij} ; \Phi)} \\
&= \frac{1}{N_j} \sum_{i \in \Omega_j} \frac{ PL_{i}^{C_{ij}} (1 - PL_{i})^{(1 -
C_{ij})} p_{ij}^{0}}{ PL_{i}^{C_{ij}} (1 -
  PL_{i})^{(1 - C_{ij})} p_{ij}^{0} + PD_{i}^{(1 - C_{ij})} (1 -
PD_{i})^{C_{ij}} (1 - p_{ij}^{0})}
\end{align}
where $i \in \Omega_j$ is now the set of classifications done on the $j$-th
image and $N_j$ is the number of classifications done on the $j$-th image. This
makes sense: $p_{ij}^{0}$ is just the prior likelihood of an image being a lens,
while $PL_{i}$ is how well we would have identified a lens as such.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\subsubsection{M-Step}
\label{sec:formalism:em:mstep}
The M-Step is done by maximizing the expected complete log-likelihood with
regard to the input parameters $PD_{i}, PL_{i}, p_{ij}^{0}$. Doing the
maximization process, we find:
\begin{align}
  PL_{i} &= \frac{\sum_{j \in \Omega_i} C_{ij} p_{j}}{\sum_{j \in
\Omega_i} p_{j}} \\
  PD_{i} &= \frac{\sum_{j \in \Omega_i} (1 - C_{ij}) (1 - p_{j})}{\sum_{j \in
\Omega_i} (1 - p_{j})}
\end{align}
\begin{align}
  p_{ij}^{0} &= p_{j} \ , &p_{i}^{0} = \frac{\sum_{j \in \Omega_i}
p_{j}}{\sum_{j \in \Omega_i} 1} \notag\\
   p_{j}^{0} &= p_{j} \ , &p^{0} = \frac{\sum_i \sum_{j \in \Omega_i}
p_{j}}{\sum_i \sum_{j \in
  \Omega_i} 1} \ ,
\end{align}
where the possible specializations of $p_0$ are also given. These mirror quite
closely the online systems, except that skill is now assessed against
the majority expectation of the probability of an image being a lens, instead
of its true value.

In practice we have training images where $p_{j}$ is known. In those
cases we can use the true value when doing the M-Step. We can also choose to
perform the M-step using only the training images (a supervised learning
approach), giving us another handle on quantifying the impact and importance of
simulated training images.

Finally, we also include Laplace smoothing into the M-Step in order to handle
pathologic cases, such as when users never identify any lenses ($\sum_{j \in
\Omega_{i}} p_j = 0$). The estimators for $PL_{i}$ and $PD_{i}$ now become:
\begin{align}
  PL_{i} &= \frac{M + \sum_{j \in \Omega_i} C_{ij} p_{j}}{2M + \sum_{j \in
\Omega_i} p_{j}} \\
  PD_{i} &= \frac{M + \sum_{j \in \Omega_i} (1 - C_{ij}) (1 - p_{j})}{2M + \sum_{j \in
\Omega_i} (1 - p_{j})}
\end{align}
where for Laplace smoothing, $M = 1$.

We choose to specialize $p^{0}$ to vary with
image, $p_{j}^{0}$, because images are taken out of the \sw system if they reach
too low a probability, clearly changing the prior when we evaluate at the end
of the run; training images also have a
different prior on being a lens as well. Finally, if the image is a training
image with known $p_j \in (0,1)$, then the known $p_j$ is used instead of
the current estimate.

An easy way to conceptualize this section is to note that the Expectation
Maximization takes advantage of the fact that each classification is supposed
to be independent of the others and so the dataset can be treated as though all
classifications were made at the same time.  The repetition of the $E$ and $M$
steps ensures that the parameters are self-consistent.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Tests}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Offline vs online}

\flag{Chris}{This section was somewhat talked about in \SW paper 1, but it
needs reiterating here.}

\begin{figure}
\begin{center}
    % \includegraphics[scale=]{sw-extended-figs/}
\end{center}
\caption{ROC curve of online vs offline for both stages}
\label{fig:offline_v_online:roc}
\end{figure}

\begin{figure}
\begin{center}
    % \includegraphics[scale=]{sw-extended-figs/}
\end{center}
\caption{Scatter plot of p values from online and offline for both stage 1 and
stage 2. Then a second plot of a similar thing but for the confusion matrices.
Show if there are any systematic differences that need to be explained}
\label{fig:offline_v_online:scatter}
\end{figure}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Unsupervised vs supervised}

\begin{figure}
\begin{center}
    % \includegraphics[scale=]{sw-extended-figs/}
\end{center}
\caption{This figure will show three sets of ROC curves: supervised only,
unsupervised only, and both together.}
\label{fig:unsupervised_v_supervised:roc}
\end{figure}

\begin{figure}
\begin{center}
    % \includegraphics[scale=]{sw-extended-figs/}
\end{center}
\caption{Scatter plot of p values using supervised only vs unsupervised +
supervised and unsupervised only. Then a second plot of a similar thing but for
the confusion matrices. The idea is to show that (probably) there is no major
systematic shift in evaluations.}
\label{fig:unsupervised_v_supervised:scatter}
\end{figure}



% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Importance of initialization}

\begin{figure}
\begin{center}
    % \includegraphics[scale=]{sw-extended-figs/}
\end{center}
\caption{This figure will show ROC curves for different initialization parameters.}
\label{fig:init:roc}
\end{figure}

\begin{figure}
\begin{center}
    % \includegraphics[scale=]{sw-extended-figs/}
\end{center}
\caption{Scatter plot of p values. Then a second plot of a similar thing but for
the confusion matrices. The idea is to show that (probably) there is no major
systematic shift in evaluations.}
\label{fig:init:scatter}
\end{figure}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Simulated vs known strong lenses}

\flag{Chris}{This section will talk about training on the small set of known
  strong lenses.  I cut down the users only to those who observed strong
  lenses. I could use as a prior the distribution of confusion matrices and
  probabilities from the training, or maybe some sort of dirichlet model. I
think it will be vital that I use an informative prior, since in my previous
explorations of this matter there simply wasn't enough data to go off of.}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Extended SpaceWarps}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

To further our understanding of the \SW model, we reran our analysis on a
subset of objects in the original dataset. This subset of objects includes all
the known lenses, objects which were deemed `unlucky misses' from having an
unlucky streak of viewers push it out of the online system, and objects that
had a large discrepancy between the offline and online systems (both supervised
and unsupervised plus supervised). In general, we found that very few objects
were missed by the offline system and found by the online system. We reran on
this dataset with the hope of finding yet more lenses. %Numbers, interface

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Extensions to Existing Model}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\subsection{Expanding Number of Classifications}
\todo{Chris}{In this section, we expand possible classifications from LENS and
  NOT to, say 0, 1, 2, 3. In effect, I take the stuff of \ref{sec:formalism:em}
  and extend it to a multinomial model. I should put in the generative model
here as well as the new confusion matrix. I have written the first several
steps below (not properly formatted and all that).}

\flag{Chris}{In the below formalism everything can only be classified once.
  That is, classification from user $i$ on subject $j$ as type $u$ is $C_{ij} =
  u$. If we want to expand classification numbers, we could say instead
$C_{iju} = 1$ for 1 classification as type $u$. Then, if you draw $M$ total
classifications, you replace $\text{Uniform}\left(p\right)$ with
$\text{Mult}\left(p, M\right)$. \\
Now you may ask: Chris, why would we ever make more than one classification on
a subject? And I would agree, except that this provides an avenue for analyzing
how to use \SW to deal with the markers (where there usually are multiple classifications).}

We can extend the \SW binomial model to include multiple classifications and
multiple categories -- we can talk about things like $P(``1" | \rm{LENSED\
QUASAR})$ where a user assigns an object a rank $``1"$ and wish to know the
likelihood that a lensed quasar would yield that category.

Unfortunately our $PL$ and $PD$ terms must be
generalized. We introduce instead $P_{ivu}$ to represent the $i$-th user's
probability of making classification $``u"$ given that the object is of type
$v$: $P_{ivu} = P(``u" | v)_i$. Naturally, the conditional probabilities are
normalized over the possible classifications $``u"$: $\sum_u^U P_{ivu} = 1$. Overall there are $U$ types of
classifications a user can make, representing $V$ types of objects.

We also must expand $p^0$ to represent more than a binary classification.
$p_{jv}^0$ is the prior probability that object $j$ is of type $v$. Naturally,
$\sum_v p_{jv}^0$ = 1.
The latent variable of subject $j$ as object $v$ is $z_{jv} = 1$ with all
other $z_{jv} = 0$. Similarly, the classification of user $i$ on subject $j$
as type $u$ is $C_{iju} = 1$ with all other $C_{iju} = 0$.
% The latent variable of subject $j$ as object $v$ is $z_{j} =
% v$. Similarly, the classification of user $i$ on subject $j$ as type $u$ is
% $C_{ij} = u$.

This is our generative model with explicit latent variables:
\begin{itemize}
  \item{Draw latent subject indicator vectors from the prior probability: $$z_{j}
    \overset{\text{iid}}{\sim} \text{Uniform}\left(p^0\right)$$}
  \item{Given latent subject indicator $z_{j}$ and the $i$-th user's confusion
    matrix $P_i$, independently draw a classification vector from the $z_j$-th column
  of $P_i$: $$C_{ij} | z_{j} \overset{\text{ind}}{\sim}
\text{Uniform}\left(P_{i,z_j}\right)$$}
\end{itemize}
Hence, we can also make the following statements:
\begin{equation}
  p(z_{jv}) = p^0_{jv}
\end{equation}
% equiv: p(z_j = v) = p^0_v
\begin{equation}
  \label{eq:PCiju}
  P(C_{iju} | z_{jv}; p^0_{jv}, P_{ivu}) = P_{ivu}^{C_{iju}}
\end{equation}

Thus our complete log likelihood is (ignoring irrelevant normalization terms)
% \begin{align}
%   \log p \left( C_{ij}, z_{j}; p_{jv}^0, P_{ivu} \right) &\propto
%                                                       \sum_{i} \sum_{j \in
%                                                       \Omega_i} \indic{z_j = v}
%                                                       \log p_{jv}^0 \notag\\
% &+ \indic{C_{ij} = u} \indic{z_j = v} \log P_{ivu}
% \end{align}
% where $\indic{}$ is the indicator function which evaluates as one when the
% contained statement is true and zero when it is false.
% \flag{Chris}{If you want to write it without indicators, expand the notation to
%   vectors and you get the following:}
\begin{align}
  \log p \left( C_{iju}, z_{jv}; p_{jv}^0, P_{ivu} \right) &\propto \sum_{i} \sum_{j \in
\Omega_i} \sum_{v} z_{jv} \log p_{jv}^0
  \notag\\
  &+ \sum_{i} \sum_{j \in \Omega_i} \sum_{v} \sum_{u} C_{iju} z_{jv} \log P_{ivu}
\end{align}

\subsubsection{E-Step}

Now we repeat the exercise earlier of computing the expected complete log
likelihood under the conditional distribution $p(z_{j} | C_{ij}; p^0,
P_{i})$. Call $p_{jv} = p(z_{jv} | C_{iju}; p^0_{jv}, P_{ivu})$. It is
sufficient to compute $p_{jv}$ to compute this step. By Bayes's Theorem, we
know that
\flag{Chris}{Is this an abuse of notation? I want for a single $z_{jv}$, but
given $C_{iju}, p^0_{jv}, P_{ivu}$ for \textit{all} $i$ and $u$. So really it
is more correct to say $ p(z_{jv}) \prod_i \prod_u p(C_{iju} | z_{jv}; p^0_{jv},
P_{ivu})$ since each classification $C_{ij}$ is independent. Should I do that?
Alternatively, I could put one of those $\cdot$ in place of each $i$ and $u$...}
$$
p(z_{jv} | C_{iju}; p^0_{jv}, P_{ivu}) \propto p(C_{iju} | z_{jv}; p^0_{jv},
P_{ivu}) p(z_{jv})
$$
But we know the values of all these terms, so we find:
\todo{Chris}{Double check this. I'm not sure it's strictly correct when you
have more than one classification per image / type.}
\begin{align}
  p_{jv} = \frac{1}{N_j} \sum_{i \in \Omega_j} \frac{p^0_{jv} \prod_u
  P_{ivu}^{C_{iju}}}{\sum_{v'} p^0_{jv'} \prod_u P_{iv'u}^{C_{iju}}}
\end{align}
where $N_j = \sum_{i \in \Omega_j} 1$.

\subsubsection{M-Step}

We maximize the expected complete log likelihood. This is straightforwardly
\todo{Chris}{Maybe not so straightforwardly if you have multiple
classifications. Check that!}
\begin{align}
  P_{ivu} &= \frac{\sum_{j \in \Omega_i} C_{iju} p_{jv}}{\sum_{j \in
\Omega_i} p_{jv}} \\
  p_{jv}^0 &= p_{jv} \\
  p_{v}^0 &= \frac{\sum_i \sum_{j \in \Omega_i} p_{jv}}{\sum_i \sum_{j \in
\Omega_i} 1}
\end{align}
where $p_{v}^0$ is a possible specialization of $p_{jv}^0$.

\subsubsection{Online}

Like in the binomial case, the multinomial case can be performed online, where
each new piece of information updates an existing assessment of lens
classification and user skill. If a new classification $C_{iju}^{(k + 1)}$ is
made, then by Bayes's Theorem the updates are as follows (with $i$, $j$, $u$,
and $v$ acting as fixed indices):
\question{Chris}{In our case, there is only one classification $u$ such that
  $C_{iju'} = 1$ if $u' = u$ and $0$ else. Is it more clear if I instead call
our classification $C_{ij}$ and multiply over all $u$ indices?}
\todo{Chris}{Double check whether the updates to $p$ and $P$ use the $k+1$ term
of the other, and if so, the ordering of it.}
\begin{align}
    p_{jv}^{(k + 1)} &= \left( \frac{(P^{k}_{ivu})^{C_{iju}^{(k + 1)}}}{\sum_{v'} p_{jv'}^{k} (P^{k}_{iv'u})^{C_{iju}^{(k+1)}}} \right) p_{jv}^{k} \\
  P^{(k+1)}_{ivu}  &= \frac{C^{(k+1)}_{iju} p^{k}_{jv} + P^{k}_{ivu} \sum_{j'\in \Omega_i} p^{k}_{j'v} }{p^{k}_{jv} + \sum_{j' \in \Omega_i} p^{k}_{j'v}} \\
  P^{(k+1)}_{ivu}  &= \left( \frac{p^{k}_{jv}}{p^{k}_{jv} + \sum_{j' \in \Omega_i} p^{k}_{j'v}} \right) C^{(k+1)}_{iju} + \left( \frac{\sum_{j'\in \Omega_i} p^{k}_{j'v}} {p^{k}_{jv} + \sum_{j'\in \Omega_i} p^{k}_{j'v}} \right) P^{k}_{ivu}
\end{align}
\question{Chris}{Do we like the first or second way of writing out
$P^{(k+1)}_{ivu}$?}
If we are using only a supervised learning set, then $p^k_{jv} \in (0, 1)$, and
$\Omega_i$ becomes instead of the set of all images classified by user $i$ the
set of all training images classified by user $i$.
\todo{Chris}{Put in the Laplace smoothing. Double check that it again is just
$M$ and $2M$ in the numerator and denominator, respectively.}

\subsubsection{Checks}
\todo{Chris}{This section will make some obvious checks on the generalized
  model. First I should be able to write down the binary model using this
  formalism. Next, I should be able to show for sure that different $u$ can
lead to different probability assignments if $v$ can only be two categories --
that is, I should be able to show that $`1'$ gives a mixture of probability for
LENS and NOT that makes sense when compared with $`0'$ or $`2'$. \\
This section can probably be removed. This is more for internal sharing to help
keep everyone up to speed.}

Let's make sure we recover the old system. In our new notation, $u$ could be
"LENS" or "NOT" while $v$ could be LENS or NOT. So, $PL_i = P_{iLL}$ and $PD_i
= P_{iNN}$. We use the conservation of total probability to note that
$P_{iLN} = 1 - P_{iLL} = 1 - PL_i$ and $P_{iNL} = 1 - P_{iNN} = 1 -
PD_i$. Meanwhile, $p_j^0$ becomes $p_{jL}^0$ and we use conservation of total
probability to note that $p_{jN}^0 = 1 - p_{j}^0$. We now account for the
labels: $z_{j} = z_{jL}$ and $z_{jN} = 1 - z_{j}$. (There can only be one
label on these objects.) Similarly for the classifications: $C_{ij} = C_{ijL}$,
so $C_{ijN} = 1 - C_{ij}$.

We can hence expand the
sums over $v \in (L, N)$ and $u \in (L, N)$ to find that our CLL is
proportional to:
\begin{align}
z_{jL} \log p_{jL}^0 + z_{jN} \log p_{jN}^0 +
C_{ijL} z_{jL} \log P_{iLL} + C_{ijN} z_{jL} \log P_{iLN} \notag\\ + C_{ijL} z_{jN} \log
P_{iNL} + C_{ijN} z_{jN} \log P_{iNN} = \notag\\
z_j \log p_j^0 + (1 - z_j) \log (1 - p_j^0) + C_{ij} z_j \log PL_i + (1 -
C_{ij}) z_j \log (1 - PL_i) \notag\\
+ C_{ij} (1 - z_j) \log (1 - PD_i) + (1 - C_{ij})
(1 - z_j) \log PD_i
\end{align}
which is the same CLL as before.

\subsubsection{Test}

\begin{figure}
\begin{center}
    % \includegraphics[scale=]{sw-extended-figs/}
\end{center}
\caption{This figure will be an ROC curve of the two subtypes in stage2 using
the above way of doing the confusion matrix. Also plotted will be the ROC
curves of the subtypes using just the binary classification. Do we do better by actually specifying? Or are we basically as well
off just taking our binary distribution and dividing up? Failure modes are:
either we don't have enough sims of each subtype to make this worthwhile, or it
doesn't help.}
\label{fig:ext:test:roc}
\end{figure}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{The Prior}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Validation of Training}
\label{sec:validation}

\todo{Chris}{In order to look at a validation dataset, I need to create a
  blacklist of agents and subjects (and decide what sort of division of either
/ both / neither constitutes a good validation dataset here) that SWAP.py can
then read in and process.}

A validation dataset is needed to prevent overfitting training data, to try
to test how the training data does against real lenses, and to train the
hyperparameters from any priors we might use. These need to come in
two categories: actual lens environments, and simulated lenses. The need for
two sets arises because of the paucity of actual lenses. In \SW, most training
objects are explicitly given to a user -- if a user incorrectly identifies a
training object, they are informed of that failure, and likewise for a correct
classification.

Problems:
0. By telling users about failures in the sim/dud, we explicitly break the
notion that users come in fully-formed. But we also need to give users
incentives to keep working, by rewarding them for good behavior. Replace by
current crowd assessments and telling them how they did compared with the
crowd?
1. \SW does not have any 'silent' training images which could function as
validation datasets, since you have broken the training by telling users.
2. How to manage the difference between 'dud known lens fields' and 'dud sim
fields'? Just put them together?
3. If you tell users about the correct sim classification, do you also tell
them about a correct lens classification, and do you tell them it was a real
lens?
4. Can I just use the dud fields?

\begin{figure}
\begin{center}
    % \includegraphics[scale=]{sw-extended-figs/}
\end{center}
\caption{This figure should have a purpose}
\label{fig:validation}
\end{figure}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Dynamic Allocations}
\todo{Chris}{This section will examine whether we would be better off
  dynamically assigning images to people (based on current estimates of skill
  and probability) rather than randomly assigning them. This means I will need
  to create some sort of 'SpaceWarps Emulator'. (Actually, the other thing
  I can do is use the blacklist developed earlier to throw out
  contributions in an informed manner in order to construct different
  simulations.) Before I even do that, another
aspect I would like to examine and is probably useful is whether we can
reliably identify skilled users early on. That is, instead of looking at final
skill vs effort, look at many trajectories of skill vs effort over time. That
would be a useful thing to show to prove that we can find the good users in the
first place -- early on!}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\subsection{Relaxing Constant Confusion Matrices}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Discussion}

\section{Conclusions}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{figure*}
% %\centering\includegraphics[width=0.9\linewidth]{sw-system-figs/sw-screengrab-marker+feedback.png}
% \caption{Screenshot of the \sw classification interface.}
% \label{fig:screenshot}
% \end{figure*}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  ACKNOWLEDGMENTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgements}

% \input{acknowledgments.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  APPENDICES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  REFERENCES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% MNRAS does not use bibtex, input .bbl file instead.
% Generate this in the makefile using bubble script in scriptutils:

% bubble -f paper-lcr.tex references.bib
% \input{paper-lcr.bbl}

\bibliographystyle{apj}
\bibliography{references}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{lastpage}
\bsp

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
